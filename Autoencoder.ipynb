{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STAtxl2nGa-7"
   },
   "source": [
    "# AUTOENCODER\n",
    "\n",
    "Tenemos una base de datos con 70000 imágenes. Utilizaremos el 60% de ellas para el training, 20% para validación y 20% para test. Para evitar overfitting en nuestro modelo implementaremos early-stopping. Aquí implementaremos el código para el autoencoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xy9CZJM2Ga-_",
    "outputId": "5cba74b5-0764-461b-b311-10d33ac088e1"
   },
   "outputs": [],
   "source": [
    "#Importamos todas las librerías que vamos a utilizar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import Models as models\n",
    "import Functions\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8Id5k0_Ga_C"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "noisy = True\n",
    "num_pixels = 56 #28\n",
    "input_size = num_pixels**2 #mismo num_pixels para H y W\n",
    "batch_size = 10\n",
    "learning_rate = 0.00001 #0.0001 #0.01\n",
    "num_im = 70000\n",
    "x_tensor = torch.zeros(num_im,num_pixels,num_pixels)\n",
    "nummax_epochs = 100\n",
    "patience = 10 #5\n",
    "periodicity = 2*np.pi\n",
    "#Variable para utilizar un autoencoder u otro (1 neurona bottleneck o el del FFN)\n",
    "fromFFN = False #True\n",
    "autoencoder_final = True #False\n",
    "norm = True # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Qat6t4_Ga_D"
   },
   "outputs": [],
   "source": [
    "if fromFFN:\n",
    "    #Auto_encod_trained\n",
    "    model_a = torch.load('/home/benjapases/Desktop/TFM_Benja/Salva3/model_trained_encoder.pth')\n",
    "    model = models.Auto_encod_trained()\n",
    "    model.layers.load_state_dict(torch.load('/home/benjapases/Desktop/TFM_Benja/Salva3/model_trained_encoder.pth'))\n",
    "\n",
    "    print((model.layers.state_dict()['2.weight']==model_a['2.weight']).all())\n",
    "\n",
    "    for p in model.layers.parameters():\n",
    "        p.requires_grad=False\n",
    "    model.layers.eval()\n",
    "        \n",
    "else:\n",
    "    if autoencoder_final:\n",
    "        state = torch.load('/home/benjapases/Desktop/TFM_Benja/Salva3/trained_decoder.t7')\n",
    "        model = models.Auto_encdec_fix()\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.decoder.parameters(), lr=learning_rate)\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "    \n",
    "    else:    \n",
    "        #Autoencoder(1 neurona bottleneck)\n",
    "        model = models.Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAMCqkYjGa_F",
    "outputId": "50f6acba-a96d-41c0-996b-e70d974c4815"
   },
   "outputs": [],
   "source": [
    "# device config (para que el codigo se ejecute en la GPU si tenemos cuda instalado)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXXYSedbGa_G",
    "outputId": "1b7d0e0c-a52d-4d20-e6c2-c792387ed18b"
   },
   "outputs": [],
   "source": [
    "#Put the directory where the images are\n",
    "#path = 'New_Images_' + str(num_pixels)\n",
    "path = 'New_Images_56noise01'\n",
    "\n",
    "for i in range(num_im):\n",
    "    name = path + '/' + 'Imagen'+ str(i) + '.png'\n",
    "    image = Image.open(name)\n",
    "    \n",
    "    #Define a transform to convert the image to tensor \n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    #Convert the image to Pytorch tensor\n",
    "    x_tensor[i] = transform(image)[0,:,:]\n",
    "\n",
    "y_tensor = x_tensor.detach().clone()\n",
    "y_tensor = y_tensor.view(y_tensor.shape[0],-1)\n",
    "\n",
    "if norm:\n",
    "    x_tensor = Functions.normalization(x_tensor)\n",
    "\n",
    "print(torch.min(y_tensor), torch.max(y_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhB7MrJzGa_H"
   },
   "outputs": [],
   "source": [
    "#Creating a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "#We create our dataset\n",
    "dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "#Divide our data into training, validation, test (60% for training, 20% validation, 20% test)\n",
    "train_len = round(0.6*num_im)\n",
    "valid_len = round(0.2*num_im)\n",
    "test_len = num_im - (train_len + valid_len)\n",
    "train_data, valid_data, test_data = torch.utils.data.random_split(dataset, [train_len,valid_len,test_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle = True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "train_tensor = torch.zeros(train_len,num_pixels,num_pixels)\n",
    "valid_tensor = torch.zeros(valid_len,num_pixels,num_pixels)\n",
    "test_tensor = torch.zeros(test_len,num_pixels,num_pixels)\n",
    "\n",
    "train_y = torch.zeros(train_len, num_pixels**2)\n",
    "valid_y = torch.zeros(valid_len, num_pixels**2)\n",
    "test_y = torch.zeros(test_len, num_pixels**2)\n",
    "\n",
    "j = 0\n",
    "for i in train_data.indices:\n",
    "    train_tensor[j] = x_tensor[i]\n",
    "    train_y[j] = y_tensor[i]\n",
    "    j+=1\n",
    "    \n",
    "j = 0\n",
    "for i in valid_data.indices:\n",
    "    valid_tensor[j] = x_tensor[i]\n",
    "    valid_y[j] = y_tensor[i]\n",
    "    j+=1\n",
    "    \n",
    "j = 0\n",
    "for i in test_data.indices:\n",
    "    test_tensor[j] = x_tensor[i]\n",
    "    test_y[j] = y_tensor[i]\n",
    "    j+=1\n",
    "\n",
    "train_dataset_norm = CustomDataset(train_tensor,train_y)\n",
    "valid_dataset_norm = CustomDataset(valid_tensor,valid_y)\n",
    "test_dataset_norm = CustomDataset(test_tensor,test_y)\n",
    "\n",
    "trainloader_norm = torch.utils.data.DataLoader(train_dataset_norm, batch_size=batch_size, shuffle=True)\n",
    "validloader_norm = torch.utils.data.DataLoader(valid_dataset_norm, batch_size=batch_size)\n",
    "testloader_norm = torch.utils.data.DataLoader(test_dataset_norm, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etDrTJosGa_K"
   },
   "outputs": [],
   "source": [
    "#Loss function\n",
    "if fromFFN:\n",
    "    optimizer = torch.optim.Adam(model.decoder.parameters(), lr=learning_rate)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SL2IIpD7Ga_L"
   },
   "outputs": [],
   "source": [
    "#We define our train model\n",
    "activ_training = []\n",
    "activ_validation = []\n",
    "activ_trainvalid = []\n",
    "epoca = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "def train(model, trainloader, validloader, optimizer, patience):\n",
    "    \"\"\"Trains a model using validation and early stopping.\n",
    "    Args:\n",
    "        model (torch.nn.modules.module.Module): Feedforward neural network.\n",
    "        trainloader (torch.utils.data.dataloader.DataLoader): Training dataset split in batches.\n",
    "        validloader (torch.utils.data.dataloader.DataLoader): Validation dataset split in batches.\n",
    "        criterion (torch.nn.modules.loss): Loss function used in the output layer.\n",
    "        optimizer (torch.optim): Optimizer to update parameters.\n",
    "        patience (int): Early stopping criteria. Number of epochs without improvement.\n",
    "    \"\"\"\n",
    "    time.sleep(0.2)  # Prevent tqdm bar to print twice\n",
    "    \n",
    "    epoch = 1\n",
    "    best_loss_valid = np.inf\n",
    "    best_model = None\n",
    "    current_patience = patience\n",
    "    \n",
    "    while True:\n",
    "        # Train\n",
    "        bar_train = tqdm(enumerate(trainloader, 1), total=len(trainloader),\n",
    "                         desc=f'Epoch {epoch:>2} (Train)')  # Progressbar to show current epoch, loss and accuracy on train\n",
    "        total_loss_train = 0\n",
    "        total_inputs_train = 0\n",
    "        model.train()\n",
    "        \n",
    "        for batch, (inputs, labels) in bar_train:\n",
    "            \n",
    "            # Reshape inputs (images to vector)\n",
    "            inputs = inputs.view(inputs.shape[0],-1)\n",
    "                        \n",
    "            # Initialize gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            #loss = criterion(labels, outputs)\n",
    "            #loss.backward()\n",
    "            loss = Functions.loss_mse(labels, outputs)\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "            # Show mean loss and accuracy in progressbar\n",
    "            total_loss_train += loss.sum().item()\n",
    "            total_inputs_train += len(labels)\n",
    "            loss_train = total_loss_train/total_inputs_train\n",
    "            bar_train.set_postfix_str(f'loss_train={loss_train:.4g}')\n",
    "                \n",
    "        # Sanity check (all training images were used)\n",
    "        assert(total_inputs_train == len(trainloader.sampler))\n",
    "        \n",
    "        # Validation\n",
    "        bar_valid = tqdm(enumerate(validloader, 1), total=len(validloader),\n",
    "                         desc=f'Epoch {epoch:>2} (Valid)')#the number 1 in enumerate means that I want number 1 to start enumerating my sampler validloader\n",
    "        total_loss_valid = 0\n",
    "        total_inputs_valid = 0\n",
    "        model.eval()  # Test mode\n",
    "        with torch.no_grad():  # Deactivates autograd to reduce memory usage\n",
    "        \n",
    "            for batch, (inputs, labels) in bar_valid:\n",
    "              \n",
    "                # Reshape inputs (images to vector)\n",
    "                inputs = inputs.view(inputs.shape[0],-1)\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss (no backprop)\n",
    "                #loss = criterion(labels, outputs)\n",
    "                loss = Functions.loss_mse(labels, outputs)\n",
    "\n",
    "                # Show mean loss and accuracy in progressbar\n",
    "                total_loss_valid += loss.sum().item()\n",
    "                total_inputs_valid += len(labels)\n",
    "                loss_valid = total_loss_valid/total_inputs_valid\n",
    "                bar_valid.set_postfix_str(f'loss_valid={loss_valid:.4g}')\n",
    "\n",
    "        # Sanity check (all validation images were used)\n",
    "        assert(total_inputs_valid == len(validloader.sampler))\n",
    "        \n",
    "    # Retrieve mean loss at validation and compare it to the best (Early stopping)\n",
    "        if loss_valid < best_loss_valid:\n",
    "            best_loss_valid = loss_valid\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            current_patience = patience\n",
    "        else:\n",
    "            current_patience -= 1\n",
    "            if current_patience <= 0:\n",
    "                model.load_state_dict(best_model)\n",
    "                break\n",
    "       \n",
    "        activ_trainvalid = activ_training + activ_validation\n",
    "    #Graph the loss in training and validation\n",
    "        plt.plot(epoch,loss_train,'b.')\n",
    "        plt.plot(epoch,loss_valid,'r.')\n",
    "        plt.title(\"Loss\",fontsize = 16)\n",
    "        plt.xlabel(\"epoch\",fontsize = 13)\n",
    "        plt.ylabel(\"loss\",fontsize = 13)\n",
    "        plt.legend([\"Training\",\"Validation\"])\n",
    "        \n",
    "        epoca.append(epoch)\n",
    "        training_loss.append(loss_train)\n",
    "        validation_loss.append(loss_valid)\n",
    "       \n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch == nummax_epochs:\n",
    "            break\n",
    "            \n",
    "    lastepoch = epoch   \n",
    "    plt.show()\n",
    "    return activ_trainvalid, lastepoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "id": "yYX_6Xy5Ga_N",
    "outputId": "d68aedb9-72df-4ec5-a4a0-a52fd3f11fbf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Execute our functions\n",
    "\n",
    "print(\"Aquí mostramos los resultados del training\")\n",
    "\n",
    "activ_trainvalid, lastepoch = train(model, trainloader_norm, validloader_norm, optimizer, patience)\n",
    "\n",
    "#Guardamos el modelo\n",
    "model_path = '/home/benjapases/Desktop/TFM_Benja/Salva3/trained_decoder.t7'\n",
    "#torch.save(model.state_dict(),model_path)\n",
    "state = {'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "torch.save(state,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jp6qug9qGa_O",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#We define our test model\n",
    "activ = []\n",
    "def test(model, testloader):\n",
    "    \"\"\"Tests a model using testloader.\n",
    "    Args:\n",
    "    model (torch.nn.modules.module.Module): Feedforward neural network.\n",
    "    testloader (torch.utils.data.dataloader.DataLoader): Test dataset split in batches.\n",
    "    trainloader (torch.utils.data.dataloader.DataLoader): Training dataset split in batches.\n",
    "    criterion (torch.nn.modules.loss): Loss function used in the output layer.\n",
    "    \"\"\"\n",
    "\n",
    "    time.sleep(0.2)  # Prevent tqdm bar to print twice\n",
    "    bar_test = tqdm(enumerate(testloader, 1), total=len(testloader),\n",
    "        desc=f'{model.__class__.__name__:<10} (Test)')\n",
    "    total_loss_test = 0\n",
    "    total_inputs_test = 0\n",
    "\n",
    "    model.eval()  # Test mode\n",
    "    with torch.no_grad():  # Deactivates autograd to reduce memory usage\n",
    "\n",
    "        for batch, (inputs, labels) in bar_test:\n",
    "            # Reshape inputs (images to vector)\n",
    "            inputs = inputs.view(inputs.shape[0], -1)\n",
    "            model.layers[-1].register_forward_hook(get_activation(''))\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss (no backprop)\n",
    "            labels = inputs\n",
    "            #loss = criterion(labels, outputs)\n",
    "            loss = Functions.loss_mse(labels, outputs)\n",
    "\n",
    "            # Show mean loss and accuracy in progressbar\n",
    "            total_loss_test += loss.sum().item()\n",
    "            total_inputs_test += len(labels)\n",
    "            loss_test = total_loss_test/total_inputs_test\n",
    "            bar_test.set_postfix_str(f'loss_test={loss_test:.4g}')\n",
    "            \n",
    "            activ.append(activation[''])\n",
    "        \n",
    "    # Sanity check (all test images were used)\n",
    "    assert(total_inputs_test == len(testloader.sampler))\n",
    "    \n",
    "    for i in range(inputs.shape[0]):\n",
    "        img = inputs[i].numpy()\n",
    "        recon = outputs[i].numpy()\n",
    "        img = img.reshape(num_pixels,num_pixels)\n",
    "        recon = recon.reshape(num_pixels,num_pixels)\n",
    "        plt.figure(figsize = (5,5))\n",
    "        plt.imshow(img)\n",
    "        plt.gray()\n",
    "        plt.figure(figsize = (5,5))\n",
    "        plt.gray()\n",
    "        plt.imshow(recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XN0J3IDfGa_P",
    "outputId": "b5c48ce1-f163-4422-a695-e7af7a5272ec"
   },
   "outputs": [],
   "source": [
    "print(\"Aquí mostramos los resultados del test\")\n",
    "\n",
    "test(model, testloader_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_JIdkQZGa_Q"
   },
   "source": [
    "En esta parte, extraemos la información de la lista activ, que nos devuelve los outputs del bottleneck, y obtenemos los mismos gráficos que para la red FFN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = []\n",
    "ox = []\n",
    "m = nn.Tanh()\n",
    "activ_test = activ\n",
    "\n",
    "for i in range(len(activ_test)):\n",
    "    o1.append(activ_test[i][:,0])\n",
    "\n",
    "for j in range(len(o1)):\n",
    "    ox = ox + o1[j].tolist()\n",
    "    \n",
    "ox = torch.tensor(ox)\n",
    "ox_activ_test = torch.acos(m(ox))*periodicity/np.pi\n",
    "print(min(ox_activ_test))\n",
    "print(max(ox_activ_test))\n",
    "\n",
    "#We save the data in txt files\n",
    "output_angle = open(\"predicted_angleAE.txt\",\"w+\")\n",
    "    \n",
    "for i in range(len(ox_activ_test)):    \n",
    "    output_angle.write(str(ox_activ_test[i])+'\\n')\n",
    "\n",
    "output_angle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_angles = np.loadtxt(path + '/' + 'angles.txt')\n",
    "noisy_angles = np.loadtxt(path + '/' + 'angles_noisy.txt')\n",
    "\n",
    "test_true_angles = []\n",
    "test_noisy_angles = []\n",
    "\n",
    "for i in test_data.indices:\n",
    "    test_true_angles.append(true_angles[i])\n",
    "    test_noisy_angles.append(noisy_angles[i])\n",
    "\n",
    "test_true_angles = np.array(test_true_angles)\n",
    "test_noisy_angles = np.array(test_noisy_angles)\n",
    "\n",
    "#We save the data in txt files\n",
    "true_anglestest = open(\"trueanglestestAE.txt\",\"w+\")\n",
    "noisy_anglestest =  open(\"noisyanglestestAE.txt\",\"w+\")  \n",
    "                         \n",
    "for i in range(len(test_true_angles)):\n",
    "    true_anglestest.write(str(test_true_angles[i]) + '\\n')\n",
    "    noisy_anglestest.write(str(test_noisy_angles[i]) + '\\n')\n",
    "                         \n",
    "                         \n",
    "true_anglestest.close()\n",
    "noisy_anglestest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ox_activ_test,test_true_angles,'.')\n",
    "plt.xlabel(\"Prediction\", fontsize = 14)\n",
    "plt.ylabel(\"Real angle\", fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ox_activ_test,test_noisy_angles,'.')\n",
    "plt.xlabel(\"Prediction\", fontsize = 14)\n",
    "plt.ylabel(\"Noisy label\", fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_noisy_angles,test_true_angles,'.')\n",
    "plt.xlabel(\"Noisy label\", fontsize = 14)\n",
    "plt.ylabel(\"Real angle\", fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calulamos el error asociado a cada salida, de la misma forma que en la red FFN, y gráficamos la densidad de probabilidad de dicho error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox_activ = np.array(ox_activ_test) \n",
    "error = Functions.circ_dist(torch.from_numpy(test_true_angles), torch.from_numpy(ox_activ), np.pi).numpy()\n",
    "abs_error = abs(error)\n",
    "\n",
    "plt.figure()\n",
    "p = sns.kdeplot(data=abs_error,cut=0,common_grid=True,common_norm=True,bw_adjust=10,linewidth=0)\n",
    "kdeline = p.lines\n",
    "x, y = kdeline[0].get_xdata(), kdeline[0].get_ydata()\n",
    "p.fill_between(x, 0, y, facecolor='blue',alpha=.2)\n",
    "plt.xlabel(r'Error',fontsize = 14)\n",
    "\n",
    "# Medians\n",
    "median = np.median(abs_error)\n",
    "#height = np.interp(median, x, y)\n",
    "#plt.vlines(median, 0, 1,linestyles='dashdot', color='#5555ff')\n",
    "plt.vlines(median, 0, 1.50,linestyles='dashdot', color='black', label='Median')\n",
    "print('Median: ', median,'\\n')\n",
    "\n",
    "#Means\n",
    "mean = np.mean(abs_error)\n",
    "#height = np.interp(mean, x, y)\n",
    "#plt.vlines(mean, 0, 1, color='blue')\n",
    "#plt.vlines(median, 0, 1, color='black', label='Mean')\n",
    "print('Mean: ', mean,'\\n')\n",
    "\n",
    "#Quartiles\n",
    "q1, q3 = np.quantile(abs_error, 0.25), np.quantile(abs_error, 0.75)\n",
    "#height1, height3 = np.interp(q1, x, y), np.interp(q3, x, y)\n",
    "plt.vlines(q1, 0, 1.50, linestyles='dashed', color='#5555ff')\n",
    "plt.vlines(q3, 0, 1.50, linestyles='dashed', color='#5555ff')\n",
    "plt.vlines(median, 0, 0.0001,linestyles='dashed', color='black', label='Quartiles')\n",
    "print('Quartiles: ', q1,q3,'\\n')\n",
    "\n",
    "#plt.xlim((0,3*q3))\n",
    "#plt.xlim((0,0.10))\n",
    "plt.xlim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "plt.grid()\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos y graficamos el error de cada salida frente a la incertidumbre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2 = []\n",
    "oy = []\n",
    "m = nn.ELU()\n",
    "\n",
    "for i in range(len(activ_test)):\n",
    "    o2.append(activ_test[i][:,1])\n",
    "\n",
    "for i in range(len(o2)):\n",
    "    oy = oy + o2[i].tolist()\n",
    "    \n",
    "oy = torch.tensor(oy)\n",
    "oy_activ = m(oy) + 1\n",
    "\n",
    "#We save our data in txt files\n",
    "output_incertidumbre = open(\"incertidumbreAE.txt\",\"w+\")\n",
    "    \n",
    "for i in range(len(oy_activ)):    \n",
    "    output_incertidumbre.write(str(oy_activ[i])+'\\n')\n",
    "\n",
    "output_incertidumbre.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oy_activ = np.array(oy_activ)\n",
    "plt.figure()\n",
    "plt.plot(oy_activ, error,'.')\n",
    "plt.ylabel(r'Error',fontsize = 14)\n",
    "plt.xlabel('Uncertainty',fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.xlim((-0.50, 0.50))\n",
    "plt.ylim((-0.50,0.50))\n",
    "#plt.ylim((-np.pi, np.pi))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si para el caso $\\textit{FFN+Decoder}$, el encoder se descarga correctamente a partir del modelo FFN previamente entrenado ($\\textit{model_trained_encoder.pth}$) y sus parámetros no se optimizan durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9Zc6S_TGa_V"
   },
   "outputs": [],
   "source": [
    "model_a = torch.load('/home/benjapases/Desktop/TFM_Benja/Salva2/model_trained_encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tp3zuMvQGa_V"
   },
   "outputs": [],
   "source": [
    "print((model.layers.state_dict()['0.weight']==model_a['0.weight']).all())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
