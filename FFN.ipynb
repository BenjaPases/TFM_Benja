{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da5d8179"
   },
   "source": [
    "# FeedForward Network (ángulos e incertidumbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a98be3d6"
   },
   "source": [
    "Vamo a hacer una red feedforward muy sencilla con dos neuronas en la salida que se corresponderán con el ángulo y la incertidumbre asociada a la predicción hecha por la red. Este modelo se corresponde con class FNN() del archivo Models.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4778,
     "status": "ok",
     "timestamp": 1660236459339,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "02779c5e",
    "outputId": "543ada3c-f508-40bc-8769-046f5b1d2e34"
   },
   "outputs": [],
   "source": [
    "#Importamos todas las librerías que vamos a utilizar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.distributions import Normal \n",
    "import seaborn as sns\n",
    "import Models as models\n",
    "import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1321,
     "status": "ok",
     "timestamp": 1660236460643,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "c3d891c7"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "noisy = True # False\n",
    "num_pixels = 56 #28\n",
    "input_size = num_pixels**2 #mismo num_pixels para H y W\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_im = 70000\n",
    "x_tensor = torch.zeros(num_im,num_pixels,num_pixels)\n",
    "num = 0\n",
    "nummax_epochs = 100\n",
    "patience = 10 # 10 # 5\n",
    "periodicity = 2*np.pi\n",
    "norm = True # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1660236460644,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "a12cf4a1"
   },
   "outputs": [],
   "source": [
    "#We call the model we'll use\n",
    "model = models.FFN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1660236460645,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "87131d48",
    "outputId": "0013f491-f8d7-413b-e9e7-28b8fabcc192"
   },
   "outputs": [],
   "source": [
    "# device config (para que el codigo se ejecute en la GPU si tenemos cuda instalado)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 132095,
     "status": "ok",
     "timestamp": 1660236592733,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "XDRq-cXcyBYZ"
   },
   "outputs": [],
   "source": [
    "#Put the directory where the images are\n",
    "path='/home/benjapases/Desktop/TFM_Benja/Salva3/New_Images_56noise01'\n",
    "os.chdir(path)\n",
    "\n",
    "for i in range(num_im):\n",
    "    name = path + '/' + 'Imagen'+ str(i) + '.png'\n",
    "    image = Image.open(name)\n",
    "    \n",
    "    #Define a transform to convert the image to tensor \n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    #Convert the image to Pytorch tensor\n",
    "    x_tensor[i] = transform(image)[0,:,:]\n",
    "\n",
    "if norm:\n",
    "    x_tensor = Functions.normalization(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1660236593164,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "1874afcc"
   },
   "outputs": [],
   "source": [
    "#Download our labels(angles.txt) and convert to tensor\n",
    "true_angles = np.loadtxt(path + '/' + 'angles.txt')\n",
    "noisy_angles = np.loadtxt(path + '/' + 'angles_noisy.txt')\n",
    "\n",
    "if noisy:\n",
    "  labels = np.cos(np.pi/periodicity*noisy_angles)\n",
    "else:\n",
    "  labels = np.cos(np.pi/periodicity*true_angles)\n",
    "y_tensor = torch.as_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1582,
     "status": "ok",
     "timestamp": 1660236594733,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "97c661fe"
   },
   "outputs": [],
   "source": [
    "#Creating a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "#We create our dataset\n",
    "dataset = CustomDataset(x_tensor, y_tensor)\n",
    "\n",
    "#Divide our data into training, validation, test (60% for training, 20% validation, 20% test)\n",
    "train_len = round(0.6*num_im)\n",
    "valid_len = round(0.2*num_im)\n",
    "test_len = num_im - (train_len + valid_len)\n",
    "train_data, valid_data, test_data = torch.utils.data.random_split(dataset, [train_len,valid_len,test_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "train_tensor = torch.zeros(train_len,num_pixels,num_pixels)\n",
    "valid_tensor = torch.zeros(valid_len,num_pixels,num_pixels)\n",
    "test_tensor = torch.zeros(test_len,num_pixels,num_pixels)\n",
    "\n",
    "l = 0\n",
    "n = 0\n",
    "k = 0\n",
    "labels_train = []\n",
    "labels_valid = []\n",
    "labels_test = []\n",
    "\n",
    "for i in train_data.indices:\n",
    "    train_tensor[l] = x_tensor[i]\n",
    "    labels_train.append(y_tensor[i])\n",
    "    l+=1\n",
    "    \n",
    "for i in valid_data.indices:\n",
    "    valid_tensor[n] = x_tensor[i]\n",
    "    labels_valid.append(y_tensor[i])\n",
    "    n+=1\n",
    "\n",
    "for i in test_data.indices:\n",
    "    test_tensor[k] = x_tensor[i]\n",
    "    labels_test.append(y_tensor[i])\n",
    "    k+=1\n",
    "\n",
    "labels_train = torch.tensor(labels_train)\n",
    "labels_valid = torch.tensor(labels_valid)\n",
    "labels_test = torch.tensor(labels_test)\n",
    "\n",
    "train_dataset_norm = CustomDataset(train_tensor,labels_train)\n",
    "valid_dataset_norm = CustomDataset(valid_tensor,labels_valid)\n",
    "test_dataset_norm = CustomDataset(test_tensor,labels_test)\n",
    "\n",
    "trainloader_norm = torch.utils.data.DataLoader(train_dataset_norm, batch_size=batch_size, shuffle=True)\n",
    "validloader_norm = torch.utils.data.DataLoader(valid_dataset_norm, batch_size=batch_size)\n",
    "testloader_norm = torch.utils.data.DataLoader(test_dataset_norm, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1660236594736,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "41b7b1fb"
   },
   "outputs": [],
   "source": [
    "#We define our train model\n",
    "activ_training = []\n",
    "activ_validation = []\n",
    "activ_trainvalid = []\n",
    "epoca = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "def train(model, trainloader, validloader, optimizer, patience):\n",
    "    \"\"\"Trains a model using validation and early stopping.\n",
    "    Args:\n",
    "        model (torch.nn.modules.module.Module): Feedforward neural network.\n",
    "        trainloader (torch.utils.data.dataloader.DataLoader): Training dataset split in batches.\n",
    "        validloader (torch.utils.data.dataloader.DataLoader): Validation dataset split in batches.\n",
    "        criterion (torch.nn.modules.loss): Loss function used in the output layer.\n",
    "        optimizer (torch.optim): Optimizer to update parameters.\n",
    "        patience (int): Early stopping criteria. Number of epochs without improvement.\n",
    "    \"\"\"\n",
    "    \n",
    "    time.sleep(0.2)  # Prevent tqdm bar to print twice\n",
    "    \n",
    "    epoch = 1\n",
    "    best_loss_valid = np.inf\n",
    "    best_model = None\n",
    "    current_patience = patience\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        # Train\n",
    "        bar_train = tqdm(enumerate(trainloader, 1), total=len(trainloader),\n",
    "                         desc=f'Epoch {epoch:>2} (Train)')  # Progressbar to show current epoch, loss and accuracy on train\n",
    "        total_loss_train = 0\n",
    "        total_inputs_train = 0\n",
    "        model.train()\n",
    "        \n",
    "        for batch, (inputs, labels) in bar_train:\n",
    "            \n",
    "            # Reshape inputs (images to vector)\n",
    "            inputs = inputs.view(inputs.shape[0],-1)\n",
    "            model.layers[-1].register_forward_hook(get_activation(''))\n",
    "            \n",
    "            # Initialize gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss = Functions.loss_gll(labels, outputs)\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Show mean loss and accuracy in progressbar\n",
    "            total_loss_train += loss.sum().item()\n",
    "            total_inputs_train += len(labels)\n",
    "            loss_train = total_loss_train/total_inputs_train\n",
    "            bar_train.set_postfix_str(f'loss_train={loss_train:.4g}')\n",
    "            \n",
    "            activ_training.append((epoch,activation['']))\n",
    "    \n",
    "        # Sanity check (all training images were used)\n",
    "        assert(total_inputs_train == len(trainloader.sampler))\n",
    "        \n",
    "        # Validation\n",
    "        bar_valid = tqdm(enumerate(validloader, 1), total=len(validloader),\n",
    "                         desc=f'Epoch {epoch:>2} (Valid)')#the number 1 in enumerate means that I want number 1 to start enumerating my sampler validloader\n",
    "        total_loss_valid = 0\n",
    "        total_inputs_valid = 0\n",
    "        model.eval()  # Test mode\n",
    "        with torch.no_grad():  # Deactivates autograd to reduce memory usage\n",
    "        \n",
    "            for batch, (inputs, labels) in bar_valid:\n",
    "              \n",
    "                # Reshape inputs (images to vector)\n",
    "                inputs = inputs.view(inputs.shape[0],-1)\n",
    "                model.layers[-1].register_forward_hook(get_activation(''))\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss (no backprop)\n",
    "                loss = Functions.loss_gll(labels, outputs)\n",
    "\n",
    "                # Show mean loss and accuracy in progressbar\n",
    "                total_loss_valid += loss.sum().item()\n",
    "                total_inputs_valid += len(labels)\n",
    "                loss_valid = total_loss_valid/total_inputs_valid\n",
    "                bar_valid.set_postfix_str(f'loss_valid={loss_valid:.4g}')\n",
    "\n",
    "                activ_validation.append((epoch,activation['']))\n",
    "                \n",
    "        # Sanity check (all validation images were used)\n",
    "        assert(total_inputs_valid == len(validloader.sampler))\n",
    "        \n",
    "    #Retrieve mean loss at validation and compare it to the best (Early stopping)\n",
    "        if loss_valid < best_loss_valid:\n",
    "            best_loss_valid = loss_valid\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            current_patience = patience\n",
    "        else:\n",
    "            current_patience -= 1\n",
    "            if current_patience <= 0:\n",
    "                model.load_state_dict(best_model)\n",
    "                break\n",
    "       \n",
    "        activ_trainvalid = activ_training + activ_validation\n",
    "    #Graph the loss in training and validation\n",
    "        plt.plot(epoch,loss_train,'b.')\n",
    "        plt.plot(epoch,loss_valid,'r.')\n",
    "        plt.title(\"Loss\",fontsize = 16)\n",
    "        plt.xlabel(\"epoch\",fontsize = 13)\n",
    "        plt.ylabel(\"loss\",fontsize = 13)\n",
    "        plt.legend([\"Training\",\"Validation\"])\n",
    "        \n",
    "        epoca.append(epoch)\n",
    "        training_loss.append(loss_train)\n",
    "        validation_loss.append(loss_valid)\n",
    "       \n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch == nummax_epochs:\n",
    "            break\n",
    "            \n",
    "    lastepoch = epoch   \n",
    "    plt.show()\n",
    "    return activ_trainvalid, lastepoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1660236594737,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "a96c52b9"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1660236594738,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "c2291b96"
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1984507,
     "status": "ok",
     "timestamp": 1660238579232,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "bd9591ea",
    "outputId": "935af8fc-0ce6-4820-f6f5-132199721e7b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Execute our functions\n",
    "\n",
    "print(\"Aquí mostramos los resultados del training\")\n",
    "\n",
    "activ_trainvalid, lastepoch = train(model, trainloader_norm, validloader_norm, optimizer, patience)\n",
    "\n",
    "#We save our model\n",
    "model_path = '/home/benjapases/Desktop/TFM_Benja/Salva3/model_trained_encoder.pth'\n",
    "#state = {'state_dict':model.layers.state_dict(),'optimizer':optimizer.state_dict()}\n",
    "torch.save(model.layers.state_dict(),model_path)\n",
    "#torch.save(state,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1660238579599,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "40189d86"
   },
   "outputs": [],
   "source": [
    "#We define our test model\n",
    "activ_test = []\n",
    "def test(model, testloader):\n",
    "    \"\"\"Tests a model using testloader.\n",
    "    Args:\n",
    "    model (torch.nn.modules.module.Module): Feedforward neural network.\n",
    "    testloader (torch.utils.data.dataloader.DataLoader): Test dataset split in batches.\n",
    "    trainloader (torch.utils.data.dataloader.DataLoader): Training dataset split in batches.\n",
    "    criterion (torch.nn.modules.loss): Loss function used in the output layer.\n",
    "    \"\"\"\n",
    "\n",
    "    time.sleep(0.2)  # Prevent tqdm bar to print twice\n",
    "    bar_test = tqdm(enumerate(testloader, 1), total=len(testloader),\n",
    "        desc=f'{model.__class__.__name__:<10} (Test)')\n",
    "    total_loss_test = 0\n",
    "    total_inputs_test = 0\n",
    "\n",
    "    model.eval()  # Test mode\n",
    "    with torch.no_grad():  # Deactivates autograd to reduce memory usage\n",
    "\n",
    "        for batch, (inputs, labels) in bar_test:\n",
    "            # Reshape inputs (images to vector)\n",
    "            inputs = inputs.view(inputs.shape[0], -1)\n",
    "            model.layers[-1].register_forward_hook(get_activation(''))\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            #print(torch.min(outputs[:,0]))\n",
    "            #print(torch.max(outputs[:,0]))\n",
    "\n",
    "            # Compute loss (no backprop)\n",
    "            loss = Functions.loss_gll(labels, outputs)\n",
    "            #loss = (labels-outputs[:,0])**2\n",
    "\n",
    "            # Show mean loss and accuracy in progressbar\n",
    "            total_loss_test += loss.sum().item()\n",
    "            total_inputs_test += len(labels)\n",
    "            loss_test = total_loss_test/total_inputs_test\n",
    "            bar_test.set_postfix_str(f'loss_test={loss_test:.4g}')\n",
    "\n",
    "            activ_test.append(activation[''])\n",
    "        \n",
    "    # Sanity check (all test images were used)\n",
    "    assert(total_inputs_test == len(testloader.sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36895,
     "status": "ok",
     "timestamp": 1660238616484,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "0dfbba31",
    "outputId": "29ae05db-a92d-4039-c5ee-ec17e1333820"
   },
   "outputs": [],
   "source": [
    "print(\"Aquí mostramos los resultados del test\")\n",
    "\n",
    "test(model, testloader_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "018875d8"
   },
   "source": [
    "Aplicamos las funciones de activación pertinentes a las salidas de la red y analizamos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1660238616877,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "5ec8f469",
    "outputId": "acd69813-a037-4cf3-e6e2-611ccc27f55a"
   },
   "outputs": [],
   "source": [
    "o1 = []\n",
    "ox = []\n",
    "m = nn.Tanh()\n",
    "\n",
    "for i in range(len(activ_test)):\n",
    "    o1.append(activ_test[i][:,0])\n",
    "\n",
    "for j in range(len(o1)):\n",
    "    ox = ox + o1[j].tolist()\n",
    "    \n",
    "ox = torch.tensor(ox)\n",
    "ox_activ_test = torch.acos(m(ox))*periodicity/np.pi\n",
    "print(min(ox_activ_test))\n",
    "print(max(ox_activ_test))\n",
    "\n",
    "#We save the data in txt files\n",
    "output_angle = open(\"predicted_angleffn.txt\",\"w+\")\n",
    "    \n",
    "for i in range(len(ox_activ_test)):    \n",
    "    output_angle.write(str(ox_activ_test[i])+'\\n')\n",
    "\n",
    "output_angle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1660238616879,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "0054f35a"
   },
   "outputs": [],
   "source": [
    "test_true_angles = []\n",
    "test_noisy_angles = []\n",
    "\n",
    "for i in test_data.indices:\n",
    "    test_true_angles.append(true_angles[i])\n",
    "    test_noisy_angles.append(noisy_angles[i])\n",
    "\n",
    "test_true_angles = np.array(test_true_angles)\n",
    "test_noisy_angles = np.array(test_noisy_angles)\n",
    "\n",
    "#We save the data in txt files\n",
    "true_anglestest = open(\"trueanglestest_ffn.txt\",\"w+\")\n",
    "noisy_anglestest =  open(\"noisyanglestest_ffn.txt\",\"w+\")  \n",
    "                         \n",
    "for i in range(len(test_true_angles)):\n",
    "    true_anglestest.write(str(test_true_angles[i]) + '\\n')\n",
    "    noisy_anglestest.write(str(test_noisy_angles[i]) + '\\n')\n",
    "                         \n",
    "                         \n",
    "true_anglestest.close()\n",
    "noisy_anglestest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos los resultados obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 832
    },
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1660238617585,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "66df5316",
    "outputId": "6262adde-b4f4-4728-e8a4-6d0518cec844"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ox_activ_test,test_true_angles,'.')\n",
    "plt.xlabel(\"Prediction\", fontsize = 14)\n",
    "plt.ylabel(\"Real angle\", fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ox_activ_test,test_noisy_angles,'.')\n",
    "plt.xlabel(\"Prediction\", fontsize = 14)\n",
    "plt.ylabel(\"Noisy label\", fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_noisy_angles,test_true_angles,'.')\n",
    "plt.xlabel(\"Noisy label\", fontsize = 14)\n",
    "plt.ylabel(\"Real angle\", fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c416a25"
   },
   "source": [
    "Calculamos el error asociado a cada salida con la función $\\textit{circ_dist}$ en el archivo $\\textit{Functions.py}$, que nos proporciona la distancia mínima entre el ángulo real y el predicho por el modelo. Finalmente, representamos la densidad de probabilidad de dicho error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1660238618029,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "de63872a",
    "outputId": "f829266b-f837-40dc-d236-4a88c4fe640b"
   },
   "outputs": [],
   "source": [
    "ox_activ = np.array(ox_activ_test)\n",
    "error = Functions.circ_dist(torch.from_numpy(test_true_angles), torch.from_numpy(ox_activ), np.pi).numpy()\n",
    "abs_error = abs(error)\n",
    "\n",
    "plt.figure()\n",
    "#p = sns.kdeplot(data=abs_error,cut=0,common_grid=True,common_norm=True,bw_adjust=10,linewidth=0)\n",
    "p = sns.kdeplot(data=abs_error,cut=0,common_grid=True,common_norm=True,linewidth=0)\n",
    "kdeline = p.lines\n",
    "x, y = kdeline[0].get_xdata(), kdeline[0].get_ydata()\n",
    "p.fill_between(x, 0, y, facecolor='blue',alpha=.2)\n",
    "plt.xlabel(r'Error',fontsize = 14)\n",
    "\n",
    "# Medians\n",
    "median = np.median(abs_error)\n",
    "#height = np.interp(median, x, y)\n",
    "#plt.vlines(median, 0, 1,linestyles='dashdot', color='#5555ff')\n",
    "plt.vlines(median, 0, 3.5,linestyles='dashdot', color='black', label='Median')\n",
    "print('Median: ', median,'\\n')\n",
    "\n",
    "#Means\n",
    "mean = np.mean(abs_error)\n",
    "#height = np.interp(mean, x, y)\n",
    "#plt.vlines(mean, 0, 1, color='blue')\n",
    "#plt.vlines(median, 0, 1, color='black', label='Mean')\n",
    "print('Mean: ', mean,'\\n')\n",
    "\n",
    "#Quartiles\n",
    "q1, q3 = np.quantile(abs_error, 0.25), np.quantile(abs_error, 0.75)\n",
    "#height1, height3 = np.interp(q1, x, y), np.interp(q3, x, y)\n",
    "plt.vlines(q1, 0, 3.5, linestyles='dashed', color='#5555ff')\n",
    "plt.vlines(q3, 0, 3.5, linestyles='dashed', color='#5555ff')\n",
    "plt.vlines(median, 0, 0.0001,linestyles='dashed', color='black', label='Quartiles')\n",
    "print('Quartiles: ', q1,q3,'\\n')\n",
    "\n",
    "#plt.xlim((0,3*q3))\n",
    "plt.xlim((0,0.37))\n",
    "plt.legend()\n",
    "\n",
    "plt.grid()\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b505d76"
   },
   "source": [
    "Ahora representamos el error frente a la incerteza obtenida con la red FFN(), es decir, la segunda salida de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1660238715278,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "a5bb1f78"
   },
   "outputs": [],
   "source": [
    "o2 = []\n",
    "oy = []\n",
    "m = nn.ELU()\n",
    "\n",
    "for i in range(len(activ_test)):\n",
    "    o2.append(activ_test[i][:,1])\n",
    "\n",
    "for i in range(len(o2)):\n",
    "    oy = oy + o2[i].tolist()\n",
    "    \n",
    "oy = torch.tensor(oy)\n",
    "oy_activ = m(oy) + 1\n",
    "\n",
    "#We save the data in txt files\n",
    "output_incertidumbre = open(\"incertidumbreffn.txt\",\"w+\")\n",
    "    \n",
    "for i in range(len(oy_activ)):    \n",
    "    output_incertidumbre.write(str(oy_activ[i])+'\\n')\n",
    "\n",
    "output_incertidumbre.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1660238752700,
     "user": {
      "displayName": "Salva Ardid",
      "userId": "01107797992888552309"
     },
     "user_tz": -120
    },
    "id": "71beb1bc",
    "outputId": "45c1ee19-cad4-4c09-84a9-7a594994ef7c"
   },
   "outputs": [],
   "source": [
    "oy_activ = np.array(oy_activ)\n",
    "plt.figure()\n",
    "plt.plot(oy_activ, error,'.')\n",
    "plt.ylabel(r'Error',fontsize = 14)\n",
    "plt.xlabel('Uncertainty',fontsize = 14)\n",
    "plt.title('$\\sigma_{noise} = 0.1$',fontsize = 14)\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FFN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
